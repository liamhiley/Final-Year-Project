\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\setcounter {tocdepth}{0}}
\@writefile{toc}{\setcounter {tocdepth}{2}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{6}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{intro}{{1}{6}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Motivation}{6}{section.1.1}}
\newlabel{motivation}{{1.1}{6}{Motivation}{section.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Project aims}{7}{section.1.2}}
\newlabel{aims}{{1.2}{7}{Project aims}{section.1.2}{}}
\citation{eyemovements}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{8}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{bg}{{2}{8}{Background}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}The science of eye tracking}{8}{section.2.1}}
\newlabel{bgeyetracking}{{2.1}{8}{The science of eye tracking}{section.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Data Processing and Analysis}{9}{section.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Clustering}{9}{subsection.2.2.1}}
\newlabel{bgclustering}{{2.2.1}{9}{Clustering}{subsection.2.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Dimensionality Reduction}{9}{subsection.2.2.2}}
\newlabel{bgdr}{{2.2.2}{9}{Dimensionality Reduction}{subsection.2.2.2}{}}
\citation{vapnik-svms}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Support Vector Machines}{10}{subsection.2.2.3}}
\newlabel{bgsvms}{{2.2.3}{10}{Support Vector Machines}{subsection.2.2.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Previous Work}{10}{section.2.3}}
\newlabel{bgprevious}{{2.3}{10}{Previous Work}{section.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces A surgical equipment tray, with spillage under the needle}}{11}{figure.2.1}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Approach}{12}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{approach}{{3}{12}{Approach}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Data Preprocessing}{12}{section.3.1}}
\newlabel{datapreproc}{{3.1}{12}{Data Preprocessing}{section.3.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Data Visualisation}{13}{section.3.2}}
\newlabel{datavis}{{3.2}{13}{Data Visualisation}{section.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Eye tracking overlay}{13}{subsection.3.2.1}}
\newlabel{overlay}{{3.2.1}{13}{Eye tracking overlay}{subsection.3.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces The first clip from the video, with the left (red), right (blue) and centre(black) gaze points of an expert}}{13}{figure.3.1}}
\citation{kmeans}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Gaze Data Clustering}{14}{subsection.3.2.2}}
\newlabel{datavisclustering}{{3.2.2}{14}{Gaze Data Clustering}{subsection.3.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Here the eye tracking data for all experts as they viewed the 3\textsuperscript  {rd} clip is clustered using GMMs}}{14}{figure.3.2}}
\citation{gmms}
\citation{overtva}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Poor clustering in the clip 7 due to objects moving along the screen}}{16}{figure.3.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Feature Extraction}{16}{section.3.3}}
\newlabel{ftextrac}{{3.3}{16}{Feature Extraction}{section.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Definition of a fixation}{17}{subsection.3.3.1}}
\newlabel{fixationdef}{{3.3.1}{17}{Definition of a fixation}{subsection.3.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Assigning clusters}{18}{subsection.3.3.2}}
\newlabel{choosingcluster}{{3.3.2}{18}{Assigning clusters}{subsection.3.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces A side-by-side comparison of the clustering of expert (right) and lay (left) data shows that expert clusters span much more of the screen and demarcate well defined regions within the scene, whereas lays only cover one half of the screen}}{18}{figure.3.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.3}Spatial features}{18}{subsection.3.3.3}}
\newlabel{spatialft}{{3.3.3}{18}{Spatial features}{subsection.3.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.4}Temporal Features}{19}{subsection.3.3.4}}
\newlabel{temporalft}{{3.3.4}{19}{Temporal Features}{subsection.3.3.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{Cluster Features}{19}{section*.6}}
\newlabel{temporalcluster}{{3.3.4}{19}{Cluster Features}{section*.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{Non-Cluster Features}{20}{section*.7}}
\newlabel{temporalnoncluster}{{3.3.4}{20}{Non-Cluster Features}{section*.7}{}}
\citation{tsne}
\citation{pca}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Dimensionality Reduction}{21}{section.3.4}}
\newlabel{dimensionalityreduc}{{3.4}{21}{Dimensionality Reduction}{section.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}t-SNE}{21}{subsection.3.4.1}}
\newlabel{drtsne}{{3.4.1}{21}{t-SNE}{subsection.3.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}PCA}{21}{subsection.3.4.2}}
\newlabel{drpca}{{3.4.2}{21}{PCA}{subsection.3.4.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Classification}{22}{section.3.5}}
\newlabel{classification}{{3.5}{22}{Classification}{section.3.5}{}}
\citation{sfs}
\citation{oneclasswgaussian}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Single-variable and pairwise classification}{23}{subsection.3.5.1}}
\newlabel{singleandpair}{{3.5.1}{23}{Single-variable and pairwise classification}{subsection.3.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Sequential Forward Selection}{23}{subsection.3.5.2}}
\newlabel{sequentialforwardselec}{{3.5.2}{23}{Sequential Forward Selection}{subsection.3.5.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.3}Classification in Principal Component space}{23}{subsection.3.5.3}}
\newlabel{classifyingpca}{{3.5.3}{23}{Classification in Principal Component space}{subsection.3.5.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.4}Fine tuning parameters}{23}{subsection.3.5.4}}
\newlabel{finetuningsvm}{{3.5.4}{23}{Fine tuning parameters}{subsection.3.5.4}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Implementation}{25}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{implementation}{{4}{25}{Implementation}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Environment}{25}{section.4.1}}
\newlabel{devenv}{{4.1}{25}{Environment}{section.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}MATLAB}{25}{subsection.4.1.1}}
\newlabel{matlab}{{4.1.1}{25}{MATLAB}{subsection.4.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Toolboxes and Libraries}{26}{section.4.2}}
\newlabel{toolbox}{{4.2}{26}{Toolboxes and Libraries}{section.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Statistics and Machine Learning Toolbox}{26}{subsection.4.2.1}}
\newlabel{statsandml}{{4.2.1}{26}{Statistics and Machine Learning Toolbox}{subsection.4.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{Clustering}{26}{section*.8}}
\newlabel{statsandmlclustering}{{4.2.1}{26}{Clustering}{section*.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{Dimensionality Reduction}{26}{section*.9}}
\newlabel{statsandmldr}{{4.2.1}{26}{Dimensionality Reduction}{section*.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{Classification}{27}{section*.10}}
\newlabel{statsandmlclassification}{{4.2.1}{27}{Classification}{section*.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}NETLAB}{27}{subsection.4.2.2}}
\newlabel{netlab}{{4.2.2}{27}{NETLAB}{subsection.4.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Algorithms}{27}{section.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Data Preprocessing}{27}{subsection.4.3.1}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {4.1}This code filters out data for the specific clip, using an array of timestamps, and the clip no. taken as an argument. It then scales the resolution down depending on the clip.}{28}{lstlisting.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Data Visualisation}{28}{subsection.4.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{Overlay}{28}{section*.11}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {4.2}This code provided the initial data visualisation necessary to disproving the feasibility of using HMMs \ref  {datavis}}{29}{lstlisting.4.2}}
\@writefile{toc}{\contentsline {subsubsection}{Clustering}{30}{section*.12}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {4.3}Here, the number of gaussians is increased every iteration until the error of the GM model increases by at least 1}{30}{lstlisting.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Classification}{30}{subsection.4.3.3}}
\@writefile{toc}{\contentsline {subsubsection}{Classification on a single variable}{30}{section*.13}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {4.4}Each variable, represented by a column of the data, is used to fit a 1 dimensional SVM, which is then cross validated, and the loss for that model estimated}{31}{lstlisting.4.4}}
\bibcite{eyemovements}{1}
\bibcite{vapnik-svms}{2}
\bibcite{overtva}{3}
\bibcite{kmeans}{4}
\bibcite{gmms}{5}
\bibcite{tsne}{6}
\bibcite{pca}{7}
\bibcite{sfs}{8}
\bibcite{oneclasswgaussian}{9}
